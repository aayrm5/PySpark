{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.3"
    },
    "colab": {
      "name": "Working_with_RDD.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/aayrm5/PySpark/blob/main/Working_with_RDD.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gjuAVgrxmIo3"
      },
      "source": [
        "# **Working with RDD (Resilient Distributed Dataset)**\n",
        "\n",
        "**`Udemy Course: Best Hands-on Big Data Practices and Use Cases using PySpark`**\n",
        "\n",
        "**`Author: Amin Karami (PhD, FHEA)`**\n",
        "\n",
        "---\n",
        "\n",
        "**Resilient Distributed Dataset (RDD)**: RDD is the fundamental data structure of Spark. It is fault-tolerant (resilient) and immutable distributed collections of any type of objects.\n",
        "\n",
        "source: https://spark.apache.org/docs/latest/rdd-programming-guide.html\n",
        "\n",
        "source: https://spark.apache.org/docs/latest/api/python/reference/"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0LWTJaC8mHL5",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "00725cbe-a604-4843-f09f-446dca5632c8"
      },
      "source": [
        "########## ONLY in Colab ##########\n",
        "!pip3 install pyspark\n",
        "########## ONLY in Colab ##########"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting pyspark\n",
            "  Downloading pyspark-3.2.1.tar.gz (281.4 MB)\n",
            "\u001b[K     |████████████████████████████████| 281.4 MB 36 kB/s \n",
            "\u001b[?25hCollecting py4j==0.10.9.3\n",
            "  Downloading py4j-0.10.9.3-py2.py3-none-any.whl (198 kB)\n",
            "\u001b[K     |████████████████████████████████| 198 kB 39.4 MB/s \n",
            "\u001b[?25hBuilding wheels for collected packages: pyspark\n",
            "  Building wheel for pyspark (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for pyspark: filename=pyspark-3.2.1-py2.py3-none-any.whl size=281853642 sha256=0ca4a79e32f5f62e5ba2cf919acede521c51720daae0a9eff26141b17a0a6131\n",
            "  Stored in directory: /root/.cache/pip/wheels/9f/f5/07/7cd8017084dce4e93e84e92efd1e1d5334db05f2e83bcef74f\n",
            "Successfully built pyspark\n",
            "Installing collected packages: py4j, pyspark\n",
            "Successfully installed py4j-0.10.9.3 pyspark-3.2.1\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "########## ONLY in Ubuntu Machine ##########\n",
        "# Load Spark engine\n",
        "# !pip3 install -q findspark\n",
        "# import findspark\n",
        "# findspark.init()\n",
        "########## ONLY in Ubuntu Machine ##########"
      ],
      "metadata": {
        "id": "K-riUQ6WTHDl"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Linking with Spark\n",
        "from pyspark import SparkContext, SparkConf"
      ],
      "metadata": {
        "id": "e3pTfRiwTMeY"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Initializing Spark\n",
        "conf = SparkConf().setAppName(\"RDD_practice\").setMaster(\"local[*]\")\n",
        "sc = SparkContext(conf=conf)\n",
        "print(sc)"
      ],
      "metadata": {
        "id": "A_ALGTfeTPN-",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "233a591b-6b09-4c37-9cb0-614a3eb3f84d"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<SparkContext master=local[*] appName=RDD_practice>\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "sc.defaultParallelism"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dX_uNHcVBTYq",
        "outputId": "88af6eb1-9af4-4f54-f724-fef54119ebe3"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "2"
            ]
          },
          "metadata": {},
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Part 1: Create RDDs and Basic Operations**\n",
        "# **There are two ways to create RDDs:**\n",
        "\n",
        "1.   Parallelizing an existing collection in your driver program\n",
        "2.   Referencing a dataset in an external storage system, such as a shared filesystem, HDFS, HBase, or any data source offering a Hadoop InputFormat."
      ],
      "metadata": {
        "id": "quQ_GBpgWLRK"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Generate random data:\n",
        "import random\n",
        "randomlist = random.sample(range(0,40), 10)\n",
        "print(randomlist)"
      ],
      "metadata": {
        "id": "ILkhrdMMTu9m",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d305ba58-4fdd-456f-b758-ac76c73d1936"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[1, 25, 2, 19, 17, 32, 29, 21, 23, 13]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Create RDD:\n",
        "rdd1 = sc.parallelize(randomlist, 4)"
      ],
      "metadata": {
        "id": "1n39Bv24XHjt"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "rdd1.getNumPartitions()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zL0o502gE0dY",
        "outputId": "08d23954-db4a-4faf-d6df-e897a752ee4c"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "4"
            ]
          },
          "metadata": {},
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Data distribution in partitions:\n",
        "rdd1.glom().collect()"
      ],
      "metadata": {
        "id": "b8aOYoMLX7Er",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b95afeb5-c679-498f-e537-0f52034e8238"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[[1, 25], [2, 19], [17, 32], [29, 21, 23, 13]]"
            ]
          },
          "metadata": {},
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Print last partition\n",
        "rdd1.glom().collect()[3]"
      ],
      "metadata": {
        "id": "9EffFOyTYC18",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f1bf16b4-e830-41e6-eb05-b99783609c37"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[29, 21, 23, 13]"
            ]
          },
          "metadata": {},
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# count():\n",
        "rdd1.count()"
      ],
      "metadata": {
        "id": "9TL1kG-Ceo6E",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a0bf9bf5-f9eb-4501-d26a-eeb5feb9766b"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "10"
            ]
          },
          "metadata": {},
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# first():\n",
        "rdd1.first()"
      ],
      "metadata": {
        "id": "gZmfAahXeryY",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "131d11bd-17c8-4c28-87b4-163d660c1648"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "1"
            ]
          },
          "metadata": {},
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# top():\n",
        "rdd1.top(5)"
      ],
      "metadata": {
        "id": "OnuGXcKLb8qa",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "1ad06143-b06e-4421-e16c-1eb39b2d30b0"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[32, 29, 25, 23, 21]"
            ]
          },
          "metadata": {},
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# distinct():\n",
        "rdd1.distinct().collect()"
      ],
      "metadata": {
        "id": "3xOj1w6teN_a",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "7d0e5619-0f2f-416f-c327-7ed8ab2f82f7"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[32, 1, 25, 17, 29, 21, 13, 2, 19, 23]"
            ]
          },
          "metadata": {},
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# map():\n",
        "rdd1.map(lambda x: x*2).collect()"
      ],
      "metadata": {
        "id": "qE0CJuhlZz1M",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "928387a3-696d-4fbb-fa1d-e4b1978dcdb6"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[2, 50, 4, 38, 34, 64, 58, 42, 46, 26]"
            ]
          },
          "metadata": {},
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# filter(): \n",
        "rdd1.filter(lambda x: x%2==0).collect()"
      ],
      "metadata": {
        "id": "r804677wamjY",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "523a8be7-863a-4943-c29a-3fe55f5f032c"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[2, 32]"
            ]
          },
          "metadata": {},
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# flatMap():\n",
        "rdd_flatmap = rdd1.flatMap(lambda x: [x+2, x+5])\n",
        "print(rdd_flatmap.collect())\n",
        "print(rdd_flatmap.reduce(lambda x,y: x+y))"
      ],
      "metadata": {
        "id": "9f--VFpvaqRj",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "7b7fe578-a4e9-454e-9259-d871139d3831"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[3, 6, 27, 30, 4, 7, 21, 24, 19, 22, 34, 37, 31, 34, 23, 26, 25, 28, 15, 18]\n",
            "434\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Descriptive statistics:\n",
        "print([\n",
        "       rdd1.max(), rdd1.min(), rdd1.mean(), rdd1.sum(), round(rdd1.stdev(),2), rdd1.top(2)\n",
        "])"
      ],
      "metadata": {
        "id": "1LSPGU35gk-q",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "df391509-8d6e-4c8d-c168-3c3b1e44b93e"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[32, 1, 18.2, 182, 9.86, [32, 29]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# mapPartitions():\n",
        "def my_func(partition):\n",
        "    sum=0\n",
        "    for item in partition:\n",
        "        sum=+item\n",
        "    yield sum\n",
        "\n",
        "rdd_mapPartition = rdd1.mapPartitions(my_func)\n",
        "rdd_mapPartition.collect()"
      ],
      "metadata": {
        "id": "PEKBDcW1bvZe",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "387f2ec7-742e-4428-e30b-40dec6e50f3e"
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[25, 19, 32, 13]"
            ]
          },
          "metadata": {},
          "execution_count": 19
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Part 2: Advanced RDD Transformations and Actions**"
      ],
      "metadata": {
        "id": "EGi2zdncaoHo"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# union():\n"
      ],
      "metadata": {
        "id": "bIKu4KMrdt1k"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# intersection():\n"
      ],
      "metadata": {
        "id": "DmQ3bNUkeMVk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Find empty partitions\n"
      ],
      "metadata": {
        "id": "E2g0ep9M8GX8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# coalesce(numPartitions):\n"
      ],
      "metadata": {
        "id": "-AopsaZqehmA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# takeSample(withReplacement, num, [seed])\n"
      ],
      "metadata": {
        "id": "OFjDbelJeuoq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# takeOrdered(n, [ordering])\n"
      ],
      "metadata": {
        "id": "_K41G_W9ezhS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# reduce():\n"
      ],
      "metadata": {
        "id": "sgBhaTdAeldY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# reduceByKey():\n"
      ],
      "metadata": {
        "id": "aj8-Q40_eXT2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# sortByKey():\n"
      ],
      "metadata": {
        "id": "Ii8M3qNMeaHC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# countByKey()\n"
      ],
      "metadata": {
        "id": "2-WYDKd2e0qf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# groupByKey():\n"
      ],
      "metadata": {
        "id": "bihcXC8DeUEv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# lookup(key):\n"
      ],
      "metadata": {
        "id": "5NzYUXEJhDM9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# cache:\n",
        "# By default, each transformed RDD may be recomputed each time you run an action on it.\n",
        "# However, you may also persist an RDD in memory using the persist (or cache) method,\n",
        "# in which case Spark will keep the elements around on the cluster for much faster access the next time you query it.\n"
      ],
      "metadata": {
        "id": "g9ThlLGO6z7u"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Persistence (https://spark.apache.org/docs/latest/rdd-programming-guide.html#rdd-persistence)\n"
      ],
      "metadata": {
        "id": "5zYpm9hpiqPc"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}